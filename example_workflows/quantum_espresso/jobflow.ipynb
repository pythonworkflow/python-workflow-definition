{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jobflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "[`jobflow`](https://materialsproject.github.io/jobflow/index.html) and [`atomate2`](https://materialsproject.github.io/atomate2/index.html) are key packages of the [Materials Project](https://materialsproject.org/) . `jobflow` was especially designed to simplify the execution of dynamic workflows -- when the actual number of jobs is dynamically determined upon runtime instead of being statically fixed before running the workflow(s). `jobflow`'s overall flexibility allows for building workflows that go beyond the usage in materials science. `jobflow` serves as the basis of `atomate2`, which implements data generation workflows in the context of materials science and will be used for data generation in the Materials Project in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define workflow with jobflow\n",
    "\n",
    "We start by importing the job decorator and Flow class from `jobflow` and the respective PWD tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jobflow import job, Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_workflow_definition.jobflow import write_workflow_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Quantum Espresso Workflow\n",
    "We will use the knowledge from the previous arithmetic workflow example to create the Quantum Espresso-related tasks for calculating an \"Energy vs. Volume\" curve. Itâ€™s important to note that this is only a basic implementation, and further extensions towards data validation or for a simplified user experience can be added. For example, one can typically configure run commands for quantum-chemical programs via configuration files in atomate2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow import (\n",
    "    calculate_qe as _calculate_qe, \n",
    "    generate_structures as _generate_structures, \n",
    "    get_bulk_structure as _get_bulk_structure, \n",
    "    plot_energy_volume_curve as _plot_energy_volume_curve,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_json_filename = \"jobflow_qe.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_qe = job(_calculate_qe)\n",
    "generate_structures = job(_generate_structures)\n",
    "plot_energy_volume_curve = job(_plot_energy_volume_curve)\n",
    "get_bulk_structure = job(_get_bulk_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We need to specify the typical QE input like pseudopotential(s) and structure model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudopotentials = {\"Al\": \"Al.pbe-n-kjpaw_psl.1.0.0.UPF\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = get_bulk_structure(\n",
    "    element=\"Al\",\n",
    "    a=4.04,\n",
    "    cubic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_mini = calculate_qe(\n",
    "    working_directory=\"mini\",\n",
    "    input_dict={\n",
    "        \"structure\": structure.output,\n",
    "        \"pseudopotentials\": pseudopotentials,\n",
    "        \"kpts\": (3, 3, 3),\n",
    "        \"calculation\": \"vc-relax\",\n",
    "        \"smearing\": 0.02,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Next, for the \"Energy vs. Volume\" curve, we meed to specify the number of strained structures and save them into a list object. For each of the strained structures, we will carry out a QE calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_strains = 5\n",
    "structure_lst = generate_structures(\n",
    "    structure=calc_mini.output.structure,\n",
    "    strain_lst=np.linspace(0.9, 1.1, number_of_strains),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_strain_lst = []\n",
    "for i in range(number_of_strains):\n",
    "    calc_strain = calculate_qe(\n",
    "        working_directory=\"strain_\" + str(i),\n",
    "        input_dict={\n",
    "            \"structure\": getattr(structure_lst.output, f\"s_{i}\"),\n",
    "            \"pseudopotentials\": pseudopotentials,\n",
    "            \"kpts\": (3, 3, 3),\n",
    "            \"calculation\": \"scf\",\n",
    "            \"smearing\": 0.02,\n",
    "        },\n",
    "    )\n",
    "    job_strain_lst.append(calc_strain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Finally, we specify a plotter for the \"Energy vs. Volume\" curve and can export the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_energy_volume_curve(\n",
    "    volume_lst=[job.output.volume for job in job_strain_lst],\n",
    "    energy_lst=[job.output.energy for job in job_strain_lst],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = Flow([structure, calc_mini, structure_lst] + job_strain_lst + [plot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_workflow_json(flow=flow, file_name=workflow_json_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {workflow_json_filename}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Workflow with aiida\n",
    "\n",
    "Now, we can import the workflow, run it with `aiida` and plot the \"Energy vs. Volume\" curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida import orm, load_profile\n",
    "\n",
    "load_profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_workflow_definition.aiida import load_workflow_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg = load_workflow_json(workflow_json_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg.nodes.get_bulk_structure1.inputs.a.value = orm.Float(4.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Workflow with pyiron_base\n",
    "\n",
    "And we can repeat the same process using `pyiron`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_workflow_definition.pyiron_base import load_workflow_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_object_lst = load_workflow_json(file_name=workflow_json_filename)\n",
    "delayed_object_lst[-1].draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_object_lst[0].input['a'] = 4.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_object_lst[-1].pull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Workflow with pyiron_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_workflow_definition.pyiron_workflow import load_workflow_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = load_workflow_json(file_name=workflow_json_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.get_bulk_structure.inputs.a.value = 4.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.draw(size=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.run()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
